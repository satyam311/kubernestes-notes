**Docs** : https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/ 

## Taints: Putting Up Fences ðŸš«

Think of taints as "only you are allowed" signs on your Kubernetes nodes. A taint marks a node with a specific characteristic, such as `"gpu=true"`. By default, pods cannot be scheduled on tainted nodes unless they have a special permission called toleration. When a toleration on a pod matches with the taint on the node then only that pod will be scheduled on that node.

---

## Tolerations: Permission Slips for Pods âœ…

Toleration allows a pod to say, "Hey, I can handle that taint. Schedule me anyway!" You define tolerations in the pod specification to let them bypass the taints.

---

Taint EffectsThe effect dictates what happens to a Pod that does not have a matching toleration for the Taint:EffectDescriptionNoSchedulePods will not be scheduled onto the Node.PreferNoScheduleThe scheduler will try to avoid scheduling Pods onto the Node (a "soft" preference).NoExecuteIf the Pod is running on the Node, it will be evicted. It also prevents new Pods from being scheduled on the Node.

## Taint Effects

The effect dictates what happens to a Pod that does not have a matching toleration for the Taint:

Effect : NoSchedule,  PreferNoSchedule, NoExecute

**NoSchedule** : Pods will not be scheduled onto the Node.
**PreferNoSchedule**: The scheduler will try to avoid scheduling Pods onto the Node (a "soft" preference).
**NoExecute**: If the Pod is running on the Node, it will be evicted. It also prevents new Pods from being scheduled on the Node. 

The **NoExecute** effect is the most aggressive of the three taint effects. Unlike NoSchedule (which only stops new Pods from landing on a Node), NoExecute applies to existing, running Pods on the Node.


## Taints & Tolerations in Action ðŸŽ¬

Hereâ€™s a breakdown of the commands to manage taints and tolerations:

### Tainting a Node:

```bash
kubectl taint nodes node1 key=gpu:NoSchedule
```

This command taints node1 with the key "gpu" and the effect "NoSchedule." Pods without a toleration for this taint won't be scheduled there.

To remove the taint , you add - at the end of the command , like below.

```bash
kubectl taint nodes node1 key=gpu:NoSchedule-
```

### Adding toleration to the pod:

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: redis
  name: redis
spec:
  containers:
  - image: redis
    name: redis
  tolerations:
  - key: "gpu"
    operator: "Equal"
    value: "true"
    effect: "NoSchedule"
```
### Limitations to Remember ðŸš§

Taints and tolerations are powerful tools, but they have limitations. They cannot handle complex expressions like "AND" or "OR." 
So, what do we use in that case? We use a combination of Taints, tolerance, and Node affinity,

--- 
## Selectors 

A Node Selector is the simplest and most basic way in Kubernetes to constrain a Pod to run only on a Node with a specific label. It is a positive constraint mechanism, meaning it guarantees placement on a particular type of node.

It works by using a simple, exact key-value match between a field in the Pod specification and a label on a Node.

### How Node Selector Works ? 

- **Label the Nodes:** The cluster administrator first applies one or more labels (key-value pairs) to the Kubernetes Nodes to describe their characteristics.
```kubectl label node node-1 disktype=ssd gpu=true```
- **Add nodeSelector to the Pod:** You add the nodeSelector field to the Pod's YAML specification, defining the exact label key-value pair(s) the Node must have.
```
  apiVersion: v1
kind: Pod
metadata:
  name: data-processor
spec:
  # This is the Node Selector field
  nodeSelector:
    disktype: ssd  # Must match the node label exactly
  containers:
  - name: app
    image: data-image
```
- **The Scheduler Matches:** When the Pod is created, the Kubernetes Scheduler checks the nodeSelector field. It will only schedule the Pod on a Node that has all the specified labels.




